# Distributed Rate Limiter as a Service

A production-grade distributed rate limiting service built with Spring Boot, Redis, and an npm SDK. Prevents API abuse across multiple server instances using atomic Lua scripts for consistent enforcement.

![Java](https://img.shields.io/badge/Java-21-orange?style=flat-square)
![Spring Boot](https://img.shields.io/badge/Spring%20Boot-3.5-green?style=flat-square)
![Redis](https://img.shields.io/badge/Redis-7-red?style=flat-square)
![TypeScript](https://img.shields.io/badge/TypeScript-5-blue?style=flat-square)
![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?style=flat-square)
![Railway](https://img.shields.io/badge/Deployed-Railway-purple?style=flat-square)
![npm](https://img.shields.io/badge/npm-@rajvardhan6403%2Frate--limiter--sdk-red?style=flat-square)

â­ If you find this project useful, please consider giving it a star â€” it helps others discover it!

---

## Live Demo

**Base URL:** `https://distributed-rate-limiter-production-82bf.up.railway.app`

Try it right now â€” no setup needed:

```bash
# Step 1 â€” Register an API key
curl -X POST https://distributed-rate-limiter-production-82bf.up.railway.app/api/v1/keys \
  -H "Content-Type: application/json" \
  -d '{"algorithm":"sliding_window","limit":5,"windowSeconds":30}'

# Step 2 â€” Use the returned apiKey to check requests (run this 6 times)
curl -X POST https://distributed-rate-limiter-production-82bf.up.railway.app/api/v1/check \
  -H "Content-Type: application/json" \
  -d '{"apiKey":"YOUR_KEY","identifier":"test-user","cost":1}'
```

The first 5 requests return `"allowed": true`. The 6th returns `"allowed": false` with HTTP 429.

---

## The Problem This Solves

Most rate limiters only work on a **single server**. When you scale to multiple instances, each server keeps its own counter â€” so a user can bypass limits by hitting different servers.

**Without this service (broken):**
```
User â†’ Server 1 â†’ counter = 1  âœ…
User â†’ Server 2 â†’ counter = 1  âœ…  (should be 2!)
User â†’ Server 3 â†’ counter = 1  âœ…  (should be 3!)
```
A user with a limit of 100 requests can actually send 300 â€” 100 to each server.

**With this service (correct):**
```
User â†’ Server 1 â†’ Redis counter = 1  âœ…
User â†’ Server 2 â†’ Redis counter = 2  âœ…
User â†’ Server 3 â†’ Redis counter = 3  âœ…
```
All servers check the same Redis counter. Limits are enforced consistently.

---

## Why This Is Better Than Alternatives

| Feature | express-rate-limit | redis-rate-limit | This Service |
|---------|-------------------|-----------------|--------------|
| Works across multiple servers | âŒ No | âœ… Yes | âœ… Yes |
| Language support | Node.js only | Node.js only | Any (HTTP API) |
| Circuit breaker / fail-open | âŒ No | âŒ No | âœ… Yes |
| Sliding window algorithm | âŒ No | Partial | âœ… Atomic Lua |
| Token bucket algorithm | âŒ No | âŒ No | âœ… Yes |
| Built-in monitoring | âŒ No | âŒ No | âœ… Prometheus + Grafana |
| Load balanced | âŒ No | âŒ No | âœ… Nginx + 2 instances |
| Self hostable | âœ… Yes | âœ… Yes | âœ… Docker Compose |

**Key advantage:** Atomic Lua scripts guarantee no race conditions even under heavy concurrent load. `express-rate-limit` uses in-memory counters that reset on restart and don't share state across servers.

---

## Architecture

```
                    Internet
                       â”‚
                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                  â”‚  Nginx  â”‚  â† Load balancer + first-layer limiting
                  â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â”‚                       â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”         â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
    â”‚  Service 1  â”‚         â”‚  Service 2  â”‚  â† Spring Boot instances
    â”‚  :8080      â”‚         â”‚  :8081      â”‚
    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜         â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
           â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                  â”Œâ”€â”€â”€â”€â–¼â”€â”€â”€â”€â”
                  â”‚  Redis  â”‚  â† Shared state (atomic counters)
                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Prometheus  â”‚â”€â”€â–¶â”‚ Grafana â”‚  â† Monitoring
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

| Component | Technology | Purpose |
|-----------|-----------|---------|
| API Service | Spring Boot 3.5 | REST endpoints, algorithm execution |
| Shared State | Redis 7 | Atomic counters, API key storage |
| Load Balancer | Nginx | Traffic distribution, first-layer limiting |
| SDK | TypeScript / npm | Client library for Node.js apps |
| Monitoring | Prometheus + Grafana | Real-time metrics and dashboards |
| Orchestration | Docker Compose | Full stack in one command |
| Deployment | Railway | Live cloud hosting |

---

## Algorithms

### Sliding Window (Recommended)

Uses a Redis Sorted Set to store timestamped request entries. Each check atomically removes expired entries, counts remaining, and adds the new request if under the limit.

```lua
-- Atomic Lua script â€” runs on Redis in one indivisible operation
redis.call('ZREMRANGEBYSCORE', key, 0, now - windowMs)
local count = redis.call('ZCARD', key)
if count < limit then
    redis.call('ZADD', key, now, requestId)
    return {1, limit - count - 1}
end
return {0, 0}
```

**Best for:** APIs where precise, consistent enforcement matters.

### Token Bucket

Stores token count and last refill time in a Redis Hash. Tokens refill continuously at a fixed rate â€” allows short bursts while controlling sustained traffic.

**Best for:** APIs where legitimate users occasionally need short bursts.

---

## How to Use It

### Option 1 â€” npm SDK (Node.js / TypeScript)

```bash
npm install @rajvardhan6403/rate-limiter-sdk
```

Basic usage:

```typescript
import { RateLimiter } from '@rajvardhan6403/rate-limiter-sdk';

const limiter = new RateLimiter({
  serviceUrl: 'https://distributed-rate-limiter-production-82bf.up.railway.app',
  apiKey: 'your-api-key',
  failOpen: true,
  timeoutMs: 3000,
});

const result = await limiter.check({ identifier: req.ip });

if (!result.allowed) {
  return res.status(429).json({ error: 'Rate limit exceeded' });
}
```

Express middleware â€” 3 lines of integration:

```typescript
import express from 'express';
import { RateLimiter } from '@rajvardhan6403/rate-limiter-sdk';

const app = express();
const limiter = new RateLimiter({
  serviceUrl: 'https://distributed-rate-limiter-production-82bf.up.railway.app',
  apiKey: 'your-api-key',
});

app.use(limiter.middleware());  // all routes are now rate limited
```

### Option 2 â€” Direct HTTP API (Any Language)

**Python:**
```python
import requests

response = requests.post(
    'https://distributed-rate-limiter-production-82bf.up.railway.app/api/v1/check',
    json={'apiKey': 'your-api-key', 'identifier': 'user-123', 'cost': 1}
)
data = response.json()
if not data['allowed']:
    print(f"Rate limited. Retry after {data['retryAfterSeconds']} seconds")
```

**Go:**
```go
resp, _ := http.Post(
    "https://distributed-rate-limiter-production-82bf.up.railway.app/api/v1/check",
    "application/json",
    strings.NewReader(`{"apiKey":"your-key","identifier":"user-123","cost":1}`),
)
```

---

## API Reference

### POST /api/v1/keys â€” Register API Key

```json
{ "algorithm": "sliding_window", "limit": 100, "windowSeconds": 60 }
```

### POST /api/v1/check â€” Check Rate Limit

```json
{ "apiKey": "abc123", "identifier": "user-456", "cost": 1 }
```

Response (200 â€” allowed):
```json
{
  "allowed": true,
  "remaining": 4,
  "resetAtEpochMs": 1234567890000,
  "retryAfterSeconds": 0,
  "limit": 5,
  "windowSeconds": 30
}
```

Response (429 â€” rate limited):
```json
{ "allowed": false, "remaining": 0, "retryAfterSeconds": 30 }
```

### GET /api/v1/keys/{apiKey} â€” Get Policy
### DELETE /api/v1/keys/{apiKey} â€” Delete Key

---

## Running Locally

### Prerequisites
- Docker Desktop
- Git

### Start Everything

```bash
git clone https://github.com/raj-deshmukh6403/distributed-rate-limiter.git
cd distributed-rate-limiter
docker compose up --build
```

| Service | URL |
|---------|-----|
| API via Nginx | http://localhost |
| Service Instance 1 | http://localhost:8080 |
| Service Instance 2 | http://localhost:8081 |
| Prometheus | http://localhost:9090 |
| Grafana | http://localhost:3000 (admin/admin) |
| Redis | localhost:6379 |

---

## Monitoring

Grafana dashboard at http://localhost:3000 shows:

- **HTTP Requests per Second** â€” traffic across both instances
- **Average Response Time** â€” latency per endpoint in ms
- **JVM Heap Memory** â€” memory usage per instance in MB
- **Live JVM Threads** â€” active threads per instance

---

## Project Structure

```
distributed-rate-limiter/
â”œâ”€â”€ service/                           # Spring Boot service
â”‚   â”œâ”€â”€ src/main/java/com/ratelimiter/service/
â”‚   â”‚   â”œâ”€â”€ algorithm/                 # SlidingWindowLimiter, TokenBucketLimiter
â”‚   â”‚   â”œâ”€â”€ controller/                # REST endpoints
â”‚   â”‚   â”œâ”€â”€ dto/                       # Request/response objects
â”‚   â”‚   â”œâ”€â”€ exception/                 # Global error handling
â”‚   â”‚   â”œâ”€â”€ repository/                # Redis API key storage
â”‚   â”‚   â””â”€â”€ service/                   # Strategy routing
â”‚   â”œâ”€â”€ src/main/resources/scripts/    # sliding_window.lua, token_bucket.lua
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ sdk/                               # TypeScript npm package
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ RateLimiter.ts
â”‚       â”œâ”€â”€ core/                      # CircuitBreaker, LocalCache
â”‚       â”œâ”€â”€ middleware/                # Express middleware
â”‚       â””â”€â”€ types/
â”œâ”€â”€ nginx/nginx.conf
â”œâ”€â”€ monitoring/
â”‚   â”œâ”€â”€ prometheus.yml
â”‚   â””â”€â”€ grafana/provisioning/
â”œâ”€â”€ Dockerfile                         # Root Dockerfile for Railway
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ railway.toml
```

---

## Design Decisions

**Why Lua scripts?** Redis executes Lua atomically â€” no race conditions possible. Two simultaneous requests cannot both read the same counter value and both get approved.

**Why fail-open?** Rate limiting is best-effort protection. If the service goes down, keeping your app running is more important than strict enforcement. The circuit breaker opens after 5 failures and retries after 30 seconds.

**Why Sorted Sets?** Each request entry is stored with its timestamp as score. One `ZREMRANGEBYSCORE` command removes all expired entries â€” exact count, no approximation.

---

## Tech Stack

| Technology | Version | Usage |
|-----------|---------|-------|
| Java | 21 | Service runtime |
| Spring Boot | 3.5 | REST API framework |
| Spring Data Redis | 3.5 | Redis client (Lettuce) |
| Lua | â€” | Atomic Redis scripts |
| TypeScript | 5 | SDK language |
| tsup | 8 | SDK bundler (ESM + CJS) |
| Axios | 1.7 | HTTP client in SDK |
| Docker + Compose | â€” | Containerisation |
| Nginx | alpine | Load balancer |
| Prometheus | latest | Metrics collection |
| Grafana | latest | Metrics visualisation |
| Micrometer | 1.15 | Spring â†’ Prometheus bridge |
| Railway | â€” | Cloud deployment |

---

## Key Points

**Distributed systems:** "Used Redis Lua scripts for atomic operations â€” ZREMRANGEBYSCORE and ZADD execute as one indivisible operation, preventing race conditions under concurrent load."

**Algorithm trade-offs:** "Sliding window stores one entry per request â€” more memory, more accurate. Token bucket stores just two values per key â€” more memory-efficient, better for bursty traffic."

**Resilience:** "Circuit breaker fails open during outages. Five failures open the circuit for 30 seconds, then one probe request tests recovery. Availability over strict enforcement."

**Developer experience:** "Three lines of Express middleware integration. The SDK handles caching, timeouts, and circuit breaking â€” the developer doesn't need to know Redis exists."

**Observability:** "Prometheus scrapes Actuator metrics every 15 seconds. Grafana shows request rate, response time, memory, and threads per instance in real time."

---

## About the Author

**Rajvardhan Deshmukh**

- GitHub: [@raj-deshmukh6403](https://github.com/raj-deshmukh6403)
- npm: [@rajvardhan6403](https://www.npmjs.com/~rajvardhan6403)

---

## Support This Project

If you found this useful:

- â­ **Star this repo** â€” helps others discover it
- ğŸ› **Found a bug?** â€” open an [issue](https://github.com/raj-deshmukh6403/distributed-rate-limiter/issues)
- ğŸ’¡ **Have an idea?** â€” open a [discussion](https://github.com/raj-deshmukh6403/distributed-rate-limiter/discussions)
- ğŸ“¦ **Using the SDK?** â€” leave a review on [npm](https://www.npmjs.com/package/@rajvardhan6403/rate-limiter-sdk)

---

## License


MIT â€” free to use, modify, and distribute.
